{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4afb02fd-52b5-43cf-a2ac-3a3050ffaa9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import requests\n",
    "warnings.simplefilter('ignore')\n",
    "import speech_recognition as sr\n",
    "# from langchain_openai import ChatOpenAI\n",
    "from langchain_core.messages import HumanMessage\n",
    "import pyttsx3\n",
    "from transformers import pipeline, set_seed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "854c6f76-1333-41bf-8352-c02acdb80006",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All PyTorch model weights were used when initializing TFGPT2LMHeadModel.\n",
      "\n",
      "All the weights of TFGPT2LMHeadModel were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFGPT2LMHeadModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "recognizer = sr.Recognizer()\n",
    "\n",
    "chat_model = pipeline('text-generation', model='gpt2')\n",
    "# chat_model = ChatOpenAI(model=\"gpt2\")\n",
    "engine = pyttsx3.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cd2900c5-d424-4bc1-b1eb-10d360da22b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b17fa7f1-a32d-4d84-be25-581bec801331",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_text(input_text):\n",
    "    message = HumanMessage(content=input_text)\n",
    "    response = chat_model(message.content , truncation=True, num_return_sequences=1)\n",
    "    return response[0]['generated_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b355ba10-65e2-4823-973a-b6961d13a232",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    run=True\n",
    "\n",
    "    while run:\n",
    "        with sr.Microphone() as source:\n",
    "            print(\"Say something...\")\n",
    "            audio = recognizer.listen(source)\n",
    "            text = recognizer.recognize_google(audio)\n",
    "            print(f\"You said: {text}\")\n",
    "    \n",
    "            action_response = process_text(text)\n",
    "            print(f\"Action Response: {action_response}\")\n",
    "    \n",
    "            engine.say(action_response)\n",
    "            engine.runAndWait()\n",
    "        ch=input(\"Do you want to Continue?(Y/N)\")\n",
    "        if ch=='N':\n",
    "            run=False\n",
    "        else:\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6d36476-4e20-44c0-b034-bdee48d5f485",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Say something...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You said: machine learning\n"
     ]
    }
   ],
   "source": [
    "warnings.simplefilter('ignore')\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "238397ce-680f-4276-beb6-b4f2f39bf573",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
