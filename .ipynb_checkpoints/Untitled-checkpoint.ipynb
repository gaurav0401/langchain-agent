{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4afb02fd-52b5-43cf-a2ac-3a3050ffaa9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import speech_recognition as sr\n",
    "# from langchain_openai import ChatOpenAI\n",
    "from langchain_core.messages import HumanMessage\n",
    "import pyttsx3\n",
    "from transformers import pipeline, set_seed\n",
    "import warnings\n",
    "import requests\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "854c6f76-1333-41bf-8352-c02acdb80006",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\Anaconda\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "WARNING:tensorflow:From D:\\Anaconda\\Lib\\site-packages\\tf_keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All PyTorch model weights were used when initializing TFGPT2LMHeadModel.\n",
      "\n",
      "All the weights of TFGPT2LMHeadModel were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFGPT2LMHeadModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "recognizer = sr.Recognizer()\n",
    "\n",
    "chat_model = pipeline('text-generation', model='gpt2')\n",
    "# chat_model = ChatOpenAI(model=\"gpt2\")\n",
    "engine = pyttsx3.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cd2900c5-d424-4bc1-b1eb-10d360da22b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b17fa7f1-a32d-4d84-be25-581bec801331",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_text(input_text):\n",
    "    message = HumanMessage(content=input_text)\n",
    "    response = chat_model(message.content ,  max_length=100, num_return_sequences=1)\n",
    "    return response[0]['generated_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b355ba10-65e2-4823-973a-b6961d13a232",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    run=True\n",
    "\n",
    "    while run:\n",
    "        with sr.Microphone() as source:\n",
    "            print(\"Say something...\")\n",
    "            audio = recognizer.listen(source)\n",
    "            text = recognizer.recognize_google(audio)\n",
    "            print(f\"You said: {text}\")\n",
    "    \n",
    "            action_response = process_text(text)\n",
    "            print(f\"Action Response: {action_response}\")\n",
    "    \n",
    "            engine.say(action_response)\n",
    "            engine.runAndWait()\n",
    "        ch=input(\"Do you want to Continue?(Y/N)\")\n",
    "        if ch=='N':\n",
    "            run=False\n",
    "        else:\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b6d36476-4e20-44c0-b034-bdee48d5f485",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Say something...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You said: machine learning\n",
      "Action Response: machine learning:\n",
      "\n",
      "A program running a neural network with no memory. (i.e. does not need more than one thread in the network.)\n",
      "\n",
      "When a program is in a large number of threads it can be useful to check the accuracy of an algorithm or to perform a comparison between numbers.\n",
      "\n",
      "The number-sensitivity algorithm of SPMP has a few limitations: the program's number of connections must be larger and the processor takes a smaller (or faster) rate of\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Do you want to Continue?(Y/N) Y\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Say something...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You said: explain Gravity\n",
      "Action Response: explain Gravity's inherent vulnerability.\n",
      "\n",
      "\n",
      "A \"drowning moment of pure emotion\":\n",
      "\n",
      "To explain the moment when you have a huge chance of winning. But most of you won't have any of these because they're not in your hands.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Do you want to Continue?(Y/N) N\n"
     ]
    }
   ],
   "source": [
    "warnings.simplefilter('ignore')\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "238397ce-680f-4276-beb6-b4f2f39bf573",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
